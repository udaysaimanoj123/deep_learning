{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udays\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "num_classes = 2\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "base_model1 = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model1.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model1.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(inputs=base_model1.input, outputs=predictions)\n",
    "\n",
    "\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen1 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "test_datagen1 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir1 = 'M-1/Training'\n",
    "test_dir1 = 'M-1/Testing'\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 32\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 2 classes.\n",
      "Found 28 images belonging to 2 classes.\n",
      "Doone\n"
     ]
    }
   ],
   "source": [
    "train_generator1 = train_datagen1.flow_from_directory(\n",
    "    train_dir1,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator1 = test_datagen1.flow_from_directory(\n",
    "    test_dir1,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "train_steps_per_epoch1 = train_generator1.n // batch_size\n",
    "test_steps_per_epoch1 = test_generator1.n // batch_size\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 56s 6s/step - loss: 0.7198 - accuracy: 0.5564\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.6627 - accuracy: 0.6327\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.6108 - accuracy: 0.6727\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.5948 - accuracy: 0.6836\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.5649 - accuracy: 0.6945\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 27s 3s/step - loss: 0.5568 - accuracy: 0.7055\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.5400 - accuracy: 0.6909\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.5505 - accuracy: 0.7382\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.5261 - accuracy: 0.7564\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 32s 3s/step - loss: 0.5155 - accuracy: 0.7273\n",
      "Doone\n"
     ]
    }
   ],
   "source": [
    "model1.fit(\n",
    "    train_generator1,\n",
    "    steps_per_epoch=train_steps_per_epoch1,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator1,\n",
    "    validation_steps=test_steps_per_epoch1\n",
    ")\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udays\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model1.save('currency_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_path='M-1/predict/canc.jpg'\n",
    "img image.load_img(img_path, target_size=(224, 224)) img_array image.img_to_array(img) =\n",
    "img_array = np.expand_dims (img_array, axis=0) img_array = 255.0 \n",
    "predictions = model1.predict(img_array)\n",
    "class_indices = np.argmax (predictions, axis=1)\n",
    "class_label = train_generator1.class_indices predicted_label = list(class_label.keys()) [list (class_label.values()).index (class_indiex)]\n",
    "print(\"Predicted class label: \", predicted_label)\n",
    "print(\"Class probabilities:\", predictions)\n",
    "class_val=0\n",
    "if predicted_label==\"canc\":\n",
    "class_val=1\n",
    "else:\n",
    "class_val=0\n",
    "print (class_val)\n",
    "print (predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 213ms/step\n",
      "Predicted class label:  non-canc\n",
      "Class probabilities: [[0.46006352 0.5399364 ]]\n",
      "0\n",
      "non-canc\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = 'M-1/predict/canc.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = img_array / 255.0  \n",
    "\n",
    "predictions1 = model1.predict(img_array)\n",
    "class_index = np.argmax(predictions1, axis=1)\n",
    "\n",
    "class_label1 = train_generator1.class_indices\n",
    "predicted_label1 = list(class_label1.keys())[list(class_label1.values()).index(class_index)]  \n",
    "\n",
    "print(\"Predicted class label: \", predicted_label1)\n",
    "print(\"Class probabilities:\", predictions1)\n",
    "m1_acc=predictions1[0][0]\n",
    "class_val1 = 0\n",
    "if predicted_label1 == \"canc\":\n",
    "    class_val1 = 1\n",
    "else:\n",
    "    class_val1 = 0\n",
    "\n",
    "print(class_val1)\n",
    "print(predicted_label1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "base_model2 = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model2.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs=base_model2.input, outputs=predictions)\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen2 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "test_datagen2 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir2 = 'M-2/ultra/training_set'\n",
    "test_dir2 = 'M-2/ultra/test_set'\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 32\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 319 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Doone\n"
     ]
    }
   ],
   "source": [
    "train_generator2 = train_datagen2.flow_from_directory(\n",
    "    train_dir2,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator2 = test_datagen2.flow_from_directory(\n",
    "    test_dir2,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "train_steps_per_epoch2 = train_generator2.n // batch_size\n",
    "test_steps_per_epoch2 = test_generator2.n // batch_size\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 31s 3s/step - loss: 0.6064 - accuracy: 0.6690\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 27s 3s/step - loss: 0.4440 - accuracy: 0.7944\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.3883 - accuracy: 0.8328\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.3347 - accuracy: 0.8502\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.3304 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.2625 - accuracy: 0.8885\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.3108 - accuracy: 0.8571\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.2332 - accuracy: 0.9059\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.2597 - accuracy: 0.8955\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 24s 3s/step - loss: 0.2141 - accuracy: 0.9233\n",
      "Doone\n"
     ]
    }
   ],
   "source": [
    "model2.fit(\n",
    "    train_generator2,\n",
    "    steps_per_epoch=train_steps_per_epoch2,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator2,\n",
    "    validation_steps=test_steps_per_epoch2\n",
    ")\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('currency_classifier2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 216ms/step\n",
      "Predicted class label:  cancer_mag\n",
      "Class probabilities: [[0.9613049  0.03869513]]\n",
      "1\n",
      "cancer_mag\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = 'M-2/ultra/single_prediction/malignant.png' \n",
    "img = image.load_img(img_path, target_size=(224, 224)) \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = img_array / 255.0 \n",
    "\n",
    "predictions2 = model2.predict(img_array)\n",
    "class_index2 = np.argmax(predictions2, axis=1)\n",
    "\n",
    "class_label2 = train_generator2.class_indices\n",
    "predicted_label2 = list(class_label2.keys())[list(class_label2.values()).index(class_index2)]  \n",
    "\n",
    "print(\"Predicted class label: \", predicted_label2)\n",
    "print(\"Class probabilities:\", predictions2)\n",
    "m2_acc=predictions2[0][0]\n",
    "class_val2 = 0\n",
    "if predicted_label2 == \"cancer_mag\":\n",
    "    class_val2 = 1\n",
    "else:\n",
    "    class_val2 = 0\n",
    "\n",
    "print(class_val2)\n",
    "print(predicted_label2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "num_classes = 2\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "base_model3 = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model3.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model3.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Model(inputs=base_model3.input, outputs=predictions)\n",
    "\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen3 = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "test_datagen3 = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dir3 = 'M-3/ultra/training_set'\n",
    "test_dir3 = 'M-3/ultra/test_set'\n",
    "\n",
    "batch_size = 32\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 319 images belonging to 2 classes.\n",
      "Found 11 images belonging to 2 classes.\n",
      "Doone\n"
     ]
    }
   ],
   "source": [
    "train_generator3 = train_datagen3.flow_from_directory(\n",
    "    train_dir3,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator3 = test_datagen3.flow_from_directory(\n",
    "    test_dir3,\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doone\n"
     ]
    }
   ],
   "source": [
    "train_steps_per_epoch3 = train_generator3.n // batch_size\n",
    "test_steps_per_epoch3 = test_generator3.n // batch_size\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.4965 - accuracy: 0.7631\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.4375 - accuracy: 0.8223\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.3443 - accuracy: 0.8537\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.3275 - accuracy: 0.8432\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.2806 - accuracy: 0.8746\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 27s 3s/step - loss: 0.2563 - accuracy: 0.8990\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.2181 - accuracy: 0.9094\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 34s 4s/step - loss: 0.2401 - accuracy: 0.8955\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 35s 4s/step - loss: 0.2452 - accuracy: 0.9132\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 40s 4s/step - loss: 0.2290 - accuracy: 0.9129\n",
      "Doone\n"
     ]
    }
   ],
   "source": [
    "model3.fit(\n",
    "    train_generator3,\n",
    "    steps_per_epoch=train_steps_per_epoch3,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator3,\n",
    "    validation_steps=test_steps_per_epoch3\n",
    ")\n",
    "print(\"Doone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('currency_classifier3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 237ms/step\n",
      "Predicted class label:  cancer_mag\n",
      "Class probabilities: [[0.994148   0.00585198]]\n",
      "1\n",
      "cancer_mag\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = 'M-3/ultra/single_prediction/malignant.png' \n",
    "img = image.load_img(img_path, target_size=(224, 224)) \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "\n",
    "predictions3 = model3.predict(img_array)\n",
    "class_index3 = np.argmax(predictions3, axis=1)\n",
    "\n",
    "class_label3 = train_generator3.class_indices\n",
    "predicted_label3 = list(class_label3.keys())[list(class_label3.values()).index(class_index3)] \n",
    "\n",
    "print(\"Predicted class label: \", predicted_label3)\n",
    "print(\"Class probabilities:\", predictions3)\n",
    "\n",
    "class_val3 = 0\n",
    "if predicted_label3 == \"cancer_mag\":\n",
    "    class_val3 = 1\n",
    "else:\n",
    "    class_val3 = 0\n",
    "m3_acc=predictions3[0][0]\n",
    "print(class_val3)\n",
    "print(predicted_label2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Cancer\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions_model1 = class_val1\n",
    "predictions_model2 = class_val2\n",
    "predictions_model3 = class_val3\n",
    "\n",
    "# print(class_val1)\n",
    "# print(class_val2)\n",
    "# print(class_val3)\n",
    "\n",
    "val_accuracy_model1 = m1_acc\n",
    "val_accuracy_model2 = m2_acc\n",
    "val_accuracy_model3 = m3_acc\n",
    "\n",
    "# print(m1_acc)\n",
    "# print(m2_acc)\n",
    "# print(m3_acc)\n",
    "\n",
    "weights = [val_accuracy_model1, val_accuracy_model2, val_accuracy_model3]\n",
    "total_weights = sum(weights)\n",
    "normalized_weights = [w / total_weights for w in weights]\n",
    "\n",
    "weighted_predictions_model1 = predictions_model1 * normalized_weights[0]\n",
    "weighted_predictions_model2 = predictions_model2 * normalized_weights[1]\n",
    "weighted_predictions_model3 = predictions_model3 * normalized_weights[2]\n",
    "\n",
    "fused_predictions = weighted_predictions_model1 + weighted_predictions_model2 + weighted_predictions_model3\n",
    "\n",
    "binary_fused_predictions = (fused_predictions >= 0.5).astype(int)\n",
    "\n",
    "print(binary_fused_predictions)\n",
    "if binary_fused_predictions == 1:\n",
    "    print(\"Cancer\")\n",
    "else:\n",
    "    print(\"No-cancer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
